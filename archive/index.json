[{"content":"这是一条测试样例 Bradley-Terry model 奖励模型一般基于BT model实现，$h_t$ $$ P(i \u0026gt; j) = \\frac{e^{\\beta_i}}{e^{\\beta_i} + e^{\\beta_j}} $$\nimport torch print(torch.rand(2, 3)).shape 你好 你好 RLHF $$ \\min_{\\theta} \\mathbb{E}\\left[ \\text{Loss}(\\theta) \\right] $$\n","permalink":"http://localhost:1313/my-blog/posts/llm-post-training/","summary":"这是一条测试样例 Bradley-Terry model 奖励模型一般基于BT model实现，$h_t$ $$ P(i \u0026gt; j) = \\frac{e^{\\beta_i}}{e^{\\beta_i} + e^{\\beta_j}} $$\nimport torch print(torch.rand(2, 3)).shape 你好 你好 RLHF $$ \\min_{\\theta} \\mathbb{E}\\left[ \\text{Loss}(\\theta) \\right] $$\n","title":"大模型post-training方法"}]